# ğŸ§ â†’ğŸ—„ï¸ NLâ€‘toâ€‘SQLÂ with Caching, **Attention Masking**, and Selfâ€‘Validation
Generate, execute, and iteratively refine _valid_ SQLite queries from naturalâ€‘language questions using OpenAI chat models.

---

## ğŸ“Œ At a Glance
| Problem | This projectâ€™s answer |
|---------|-----------------------|
| Large schema, irrelevant tables â†’ hallucinated joins | **Entityâ€‘aware *soft masking*** â€“ numeric weights hint the model toward relevant tables/columns. |
| Unreliable SQL from LLM | **Execution + feedback loop** â€“ run the query, analyse results, regenerate up to 3Ã—. |
| Slow schema access | **Onâ€‘disk cache** (`./schema_cache/*.json`). |
| Need auditability | Full attempt history with validation feedback in `feedback_<mode>.json`. |

---

## ğŸ›   Core Pipeline

```text
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ eval.json   â”‚  (Q, db_id, evidence)
          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
        1. SchemaCache        (DDL + columns â†’ JSON)
                â”‚
        2. Entity / relation extraction (SpaCy)
                â”‚
        3. Map â†’ relevant tables/columns
                â”‚
        4. Build â˜… ATTENTION MASK â˜…
                â”‚
        5. Compose prompt (fewâ€‘shot + CoT + mask)
                â”‚
        6. Call OpenAI        (retry & timeout)
                â”‚
        7. Execute SQL on SQLite
                â”‚
        8. Validate â†’ feedback â†’ regenerate (â‰¤3)
                â”‚
          â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
          â”‚ Outputs    â”‚  predict_*.json â€¢ feedback_*.json
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯  Attention / Masking Mechanism

1. **Entity & dependency mining**  
   SpaCy detects named entities _and_ subject/â€‹object pairs in the question.

2. **Schema mapping â†’ weights**  
   *â€¯+1.0â€¯* for exact hits on table/column names.  
   *â€¯+0.5â€¯* extra if either side of a dependency pair appears.  
   Nonâ€‘relevant elements receive a floor weight of **0.3**.

3. **Soft mask, not hard filter**  
   The weights are **exposed inside the prompt** in two ways:

   *Inline comments*â€¯inside each `CREATE TABLE â€¦`:

   ```sql
   CREATE TABLE orders (
       order_id INTEGER PRIMARY KEY,          -- AttentionÂ Weight: 1.5
       order_date TEXT                        -- AttentionÂ Weight: 1.5
   ) -- AttentionÂ Weight: 1.5
   ```

   *Standalone block*:

   ```
   ### Schema Attention Weights ###
   orders: 1.5
   orders.order_date: 1.5
   customers: 0.3
   ...
   ```

   > The LLM remains free to use any part of the schema, but higherâ€‘weighted
   > elements are statistically more likely to be selected â€“ a **soft mask**.

---

## âœ¨  Feature Table
| Area | Details |
|------|---------|
| **Schema cache** | JSON snapshot of DDL + columns for each DB (`SchemaCache`). |
| **Fewâ€‘shot** | Oneâ€‘shot demo (with or without external knowledge). |
| **Chainâ€‘ofâ€‘Thought (optional)** | `--chain_of_thought True` injects a CoT instruction but strips CoT from final answer. |
| **Selfâ€‘validation loop** | Up to 3 cycles: execute â†’ analyse â†’ feedback â†’ regenerate. |
| **Confidence scoring** | Combines execution success, row count, and issue count. |
| **Timeouts & retries** | `signal.alarm` for code/DB, `backoff` for rateâ€‘limits. |

---

## ğŸ“¦  Installation

```bash
python -m venv venv
source venv/bin/activate  # Windows: .env\Scriptsctivate
pip install -U openai backoff sqlparse tqdm spacy
python -m spacy download en_core_web_sm
```

> `signal.alarm` requires POSIX (Linux/macOS). On Windows use WSL or adapt to `multiprocessing`.

---

## ğŸ—‚  Data Layout

```
project/
â”œâ”€â”€ databases/
â”‚   â””â”€â”€ <db_id>/<db_id>.sqlite
â””â”€â”€ eval/
    â””â”€â”€ eval.json
```

`eval.json` object schema:

```json
{
  "question": "How many orders were shipped to Canada in 2024?",
  "db_id":    "northwind",
  "evidence": "Canada appears in the 'Customers' table under 'Country'."
}
```

---

## ğŸš€  Usage

```bash
export OPENAI_API_KEY="sk-..."   # or pass via --api_key

python nl2sql_validate.py   --eval_path          eval/eval.json   --mode               dev   --db_root_path       databases   --api_key            $OPENAI_API_KEY   --engine             gpt-4o   --data_output_path   outputs/   --feedback_output_path outputs/feedback_dev.json   --use_knowledge      False   --chain_of_thought   False
```

Outputs:

```
outputs/
â”œâ”€â”€ predict_dev.json   # {int: SQL string}
â””â”€â”€ feedback_dev.json  # perâ€‘question attempt log
```

---

## âš ï¸  Limitations / TODO

* `--use_knowledge` flag is parsed but not yet threaded into prompt builder (quick fix needed).
* Path join assumes `--data_output_path` ends with `/`; switch to `os.path.join`.
* Windows: replace `signal.alarm`.

---

## ğŸ“  License

MIT License â€” see `LICENSE`.

> Found a bug or have an improvement? PRs welcome!
